{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne \n",
    "from nice.markers import (KolmogorovComplexity, TimeLockedContrast, PowerSpectralDensityEstimator, \n",
    "                          PowerSpectralDensity, SymbolicMutualInformation, PermutationEntropy, TimeLockedTopography, ContingentNegativeVariation)\n",
    "\n",
    "import pycsd\n",
    "\n",
    "from utils import make_str_label, all_markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute markers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_markers(epochs, tmin, tmax, target):\n",
    "        \"\"\"\n",
    "        Computes all ther markers for given epochs.\n",
    "        epochs: the epochs from which to compute the markers\n",
    "        tmin: min time for computing markers \n",
    "        tmax: max time to compute markers\n",
    "        \n",
    "        Evoked markers have already defined times\n",
    "        \"\"\"\n",
    "        from scipy.stats import trim_mean\n",
    "        \n",
    "        def trim_mean80(a, axis=0):\n",
    "            return trim_mean(a, proportiontocut=.1, axis=axis)       \n",
    "\n",
    "        # =============================================================================\n",
    "        # SPECTRAL MARKERS\n",
    "        # =============================================================================\n",
    "          #PowerSpectralDensityL\n",
    "        psds_params = dict(n_fft=4096, n_overlap=100, n_jobs='auto', nperseg=128)\n",
    "        base_psd = PowerSpectralDensityEstimator(\n",
    "            psd_method='welch', tmin=tmin, tmax=tmax, fmin=1., fmax=45.,\n",
    "            psd_params=psds_params, comment='default')\n",
    "        \n",
    "\n",
    "\n",
    "        ###alpha normalized###\n",
    "        alpha = PowerSpectralDensity(estimator=base_psd, fmin=8., fmax=13.,normalize=True, comment='alphan')\n",
    "        alpha.fit(epochs)\n",
    "\n",
    "        reduction_func = [{'axis': 'frequency', 'function': np.sum},\n",
    "             {'axis': 'channels', 'function': np.mean},\n",
    "             {'axis': 'epochs', 'function': trim_mean80}]\n",
    "        ###alpha normalized###\n",
    "        alpha = PowerSpectralDensity(estimator=base_psd, fmin=8., fmax=13.,normalize=True, comment='alpha')\n",
    "        alpha.fit(epochs)\n",
    "        dataalpha_n = alpha._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        #alpha\n",
    "        alpha = PowerSpectralDensity(estimator=base_psd, fmin=8., fmax=13.,normalize=False, comment='alpha')\n",
    "        alpha.fit(epochs)\n",
    "        dataalpha = alpha._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        #delta normalized\n",
    "        delta = PowerSpectralDensity(estimator=base_psd, fmin=1., fmax=4.,normalize=True, comment='delta')\n",
    "        delta.fit(epochs)\n",
    "        datadelta_n = delta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        #delta\n",
    "        delta = PowerSpectralDensity(estimator=base_psd, fmin=1., fmax=4,normalize=False, comment='delta')\n",
    "        delta.fit(epochs)\n",
    "        datadelta = delta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        #theta normalized\n",
    "        theta = PowerSpectralDensity(estimator=base_psd, fmin=4., fmax=8.,normalize=True, comment='theta')\n",
    "        theta.fit(epochs)\n",
    "        datatheta_n = theta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        #theta\n",
    "        theta = PowerSpectralDensity(estimator=base_psd, fmin=4., fmax=8,normalize=False, comment='theta')\n",
    "        theta.fit(epochs)\n",
    "        datatheta = theta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        #gamma normalized\n",
    "        gamma = PowerSpectralDensity(estimator=base_psd, fmin=30., fmax=45.,normalize=True, comment='gamma')\n",
    "        gamma.fit(epochs)\n",
    "        datagamma_n = gamma._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        #gamma\n",
    "        gamma = PowerSpectralDensity(estimator=base_psd, fmin=30., fmax=45,normalize=False, comment='theta')\n",
    "        gamma.fit(epochs)\n",
    "        datagamma = gamma._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        #beta normalized\n",
    "        beta = PowerSpectralDensity(estimator=base_psd, fmin=13., fmax=30.,normalize=True, comment='beta')\n",
    "        beta.fit(epochs)\n",
    "        databetaa_n = beta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        #beta\n",
    "        beta = PowerSpectralDensity(estimator=base_psd, fmin=13., fmax=30,normalize=False, comment='beta')\n",
    "        beta.fit(epochs)\n",
    "        databeta = beta._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        # =============================================================================\n",
    "        # INFORMATION THEORY MARKERS\n",
    "        # =============================================================================\n",
    "\n",
    "        komplexity = KolmogorovComplexity(tmin=tmin, tmax=tmax, backend='openmp')\n",
    "        komplexity.fit(epochs)\n",
    "        komplexityobject=komplexity.data_ ###Object to save, number of channels*number of epochs, it's ndarray\n",
    "        reduction_func= [{'axis': 'channels', 'function': np.mean},\n",
    "             {'axis': 'epochs', 'function': trim_mean80}]\n",
    "\n",
    "\n",
    "        datakomplexity = komplexity._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "\n",
    "        p_e = PermutationEntropy(tmin=tmin, tmax=tmax)\n",
    "        p_e.fit(epochs)\n",
    "        p_eobject = p_e.data_\n",
    "        datap_e = p_e._reduce_to(reduction_func, target=target, picks=None)\n",
    "\n",
    "        # =============================================================================\n",
    "        # wSMI MARKERS\n",
    "        # =============================================================================\n",
    "        wSMI = SymbolicMutualInformation(tmin=tmin, tmax=tmax, kernel=3, tau=8, backend=\"openmp\",\n",
    "                     method_params=None, method='weighted', comment='default')\n",
    "        wSMI.fit(epochs)\n",
    "        wSMIobject = wSMI.data_\n",
    "\n",
    "        reduction_func= [{'axis': 'channels_y', 'function': np.median},\n",
    "             {'axis': 'channels', 'function': np.mean},\n",
    "             {'axis': 'epochs', 'function': trim_mean80}]\n",
    "        \n",
    "        datawSMI = wSMI._reduce_to(reduction_func, target=target, picks=None)\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # EVOKED MARKERS\n",
    "        # =============================================================================\n",
    "        \n",
    "        ###Contingent Negative Variation (CNV)###\n",
    "        cnv = ContingentNegativeVariation(tmin=-0.004, tmax=0.596)\n",
    "        \n",
    "        reduction_func = [{'axis': 'epochs', 'function': trim_mean80},\n",
    "             {'axis': 'channels', 'function': np.mean}]\n",
    "        \n",
    "        cnv.fit(epochs)\n",
    "        cnv_chs= ['AF3', 'AFz', 'AF4', 'F1', 'Fz', 'F2', 'FC1', 'FCz', 'FC2']\n",
    "        roi_cnv = np.array(mne.pick_channels(epochs.info['ch_names'], include=cnv_chs))\n",
    "        dataCNV = cnv._reduce_to(reduction_func, target=target, picks={\n",
    "        'epochs': None,\n",
    "        'channels': roi_cnv})\n",
    "        \n",
    "        ###P1###\n",
    "        reduction_func = [{'axis': 'epochs', 'function': trim_mean80},\n",
    "         {'axis': 'channels', 'function': np.mean},\n",
    "         {'axis': 'times', 'function': np.mean}]\n",
    "        p1 = TimeLockedTopography(tmin=0.068, tmax=0.116, comment='p1')\n",
    "        p1.fit(epochs)\n",
    "        p1_chs= ['AF3', 'AFz', 'AF4', 'F1', 'Fz', 'F2', 'FC1', 'FCz', 'FC2']\n",
    "        roi_p1 = np.array(mne.pick_channels(epochs.info['ch_names'], include=p1_chs))\n",
    "        dataP1 = p1._reduce_to(reduction_func, target=target, picks={\n",
    "        'epochs': None,\n",
    "        'channels': roi_p1,\n",
    "        'times':None})\n",
    "        \n",
    "        ###P3a###\n",
    "        p3a = TimeLockedTopography(tmin=0.28, tmax=0.34, comment='p3a')\n",
    "        reduction_func = [{'axis': 'epochs', 'function': trim_mean80},\n",
    "         {'axis': 'channels', 'function': np.mean},\n",
    "         {'axis': 'times', 'function': np.mean}]\n",
    "        p3a.fit(epochs)\n",
    "        p3a_chs= ['AF3', 'AFz', 'AF4', 'F1', 'Fz', 'F2', 'FC1', 'FCz', 'FC2']\n",
    "        roi_p3a = np.array(mne.pick_channels(epochs.info['ch_names'], include=p3a_chs))\n",
    "        dataP3a= p3a._reduce_to(reduction_func, target=target, picks={\n",
    "        'epochs': None,\n",
    "        'channels': roi_p3a,\n",
    "        'times':None})\n",
    "        \n",
    "        ###P3b###\n",
    "        p3b = TimeLockedTopography(tmin=0.4, tmax=0.6, comment='p3a')\n",
    "        reduction_func = [{'axis': 'epochs', 'function': trim_mean80},\n",
    "         {'axis': 'channels', 'function': np.mean},\n",
    "         {'axis': 'times', 'function': np.mean}]\n",
    "        p3b.fit(epochs)\n",
    "        p3b_chs= ['FC1', 'FCz', 'FC2', 'C1', 'Cz','C2', 'CP1', 'CPz', 'CP2']\n",
    "        roi_p3b = np.array(mne.pick_channels(epochs.info['ch_names'], include=p3b_chs))\n",
    "        dataP3b= p3b._reduce_to(reduction_func, target=target, picks={\n",
    "        'epochs': None,\n",
    "        'channels': roi_p3b,\n",
    "        'times':None})\n",
    "        \n",
    "        ###Dictionary with all the markers###\n",
    "        return {'wSMI':datawSMI, 'p_e':datap_e, 'k':datakomplexity, 'b':databeta,'b_n':databetaa_n, 'g':datagamma, 'g_n':datagamma_n, 't':datatheta,'t_n': datatheta_n , 'd':datadelta,\n",
    "        'd_n':datadelta_n, 'a_n':dataalpha_n, 'a':dataalpha, 'CNV':dataCNV, 'P1':dataP1, 'P3a': dataP3a, 'P3b': dataP3b}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_type = 'evoked'\n",
    "# epoch_type = 'pseudo-rs'\n",
    "\n",
    "\n",
    "all_participants = ['VP07','VP08','VP09', 'VP10','VP11','VP12','VP13','VP14','VP18','VP19','VP20','VP22','VP23','VP24','VP25','VP26','VP27','VP28','VP29','VP30','VP31','VP32','VP33','VP35','VP36','VP37']\n",
    "\n",
    "\n",
    "# path = '/media/nicolas.bruno/63f8a366-34b7-4896-a7ce-b5fb4ee78535/Nico/MW_eeg_data/minmarker/' #icm-linux\n",
    "path = '/Users/nicobruno/ownCloud/MW_eeg_data/minmarker/' #nico-mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute markers for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#########################################\n",
      "Computing markers for participant VP07\n",
      "#########################################\n",
      "\n",
      "Reading /Users/nicobruno/ownCloud/MW_eeg_data/minmarker/VP07/VP07_evoked_ar_subtracted_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     600.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "174 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Cannot autodetect number of jobs\n",
      "Effective window size : 16.384 (s)\n",
      "Reduction order for nice/marker/PowerSpectralDensity/alpha: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/alpha: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/delta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/delta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/theta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/theta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/gamma: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/theta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/beta: ['frequency', 'epochs']\n",
      "Reduction order for nice/marker/PowerSpectralDensity/beta: ['frequency', 'epochs']\n",
      "Running KolmogorovComplexity\n",
      "Elapsed time 0.32901883125305176 sec\n",
      "Reduction order for nice/marker/KolmogorovComplexity/default: ['epochs']\n",
      "Filtering  at 10.42 Hz\n",
      "Performing symbolic transformation\n",
      "Reduction order for nice/marker/PermutationEntropy/default: ['epochs']\n",
      "Cannot autodetect number of jobs\n",
      "Computing CSD\n",
      "Fitted sphere radius:         95.0 mm\n",
      "Origin head coordinates:      0.0 -0.0 40.1 mm\n",
      "Origin device coordinates:    0.0 -0.0 40.1 mm\n",
      "Filtering  at 10.42 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicobruno/opt/anaconda3/lib/python3.8/site-packages/nice-0.1.dev0-py3.8.egg/nice/algorithms/information_theory/permutation_entropy.py:75: RuntimeWarning: divide by zero encountered in log\n",
      "  pe = np.nan_to_num(-np.nansum(count * np.log(count), axis=1))\n",
      "/Users/nicobruno/opt/anaconda3/lib/python3.8/site-packages/nice-0.1.dev0-py3.8.egg/nice/algorithms/information_theory/permutation_entropy.py:75: RuntimeWarning: invalid value encountered in multiply\n",
      "  pe = np.nan_to_num(-np.nansum(count * np.log(count), axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction order for nice/marker/SymbolicMutualInformation/default: ['channels_y', 'epochs']\n",
      "Reduction order for nice/marker/ContingentNegativeVariation/default: ['epochs']\n",
      "Reduction order for nice/marker/TimeLockedTopography/p1: ['epochs', 'times']\n",
      "Reduction order for nice/marker/TimeLockedTopography/p3a: ['epochs', 'times']\n",
      "Reduction order for nice/marker/TimeLockedTopography/p3a: ['epochs', 'times']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (174) does not match length of index (64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-fb579c7a8bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdf_subtracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_markers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_subtracted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     df_subtracted = df_subtracted.assign(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs_subtracted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_str_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3829\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3830\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3242\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \"\"\"\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (174) does not match length of index (64)"
     ]
    }
   ],
   "source": [
    "target = 'epochs'\n",
    "\n",
    "for i in all_participants:\n",
    "    participant = i\n",
    "    \n",
    "    print('')\n",
    "    print('#########################################')\n",
    "    print('Computing markers for participant {}'.format(participant))\n",
    "    print('#########################################')\n",
    "    print('')\n",
    "    \n",
    "\n",
    "    folder = path + participant +'/'\n",
    "\n",
    "    \n",
    "    df_markers = pd.DataFrame()\n",
    "    df_markers['participant'] = participant\n",
    "    \n",
    "    #############################\n",
    "    #### With ERP SUBTRACTED ####\n",
    "    #############################\n",
    "    epochs_subtracted = mne.read_epochs(folder +  participant + '_' + epoch_type + '_' +  'ar_subtracted_epo.fif') \n",
    "    epochs_subtracted.info['description'] = 'biosemi/64' #necessary for wSMI \n",
    "    epochs_subtracted =  epochs_subtracted.pick_types(eeg = True) #EOGs break everything\\\n",
    "    \n",
    "    df_subtracted = pd.DataFrame.from_dict(all_markers(epochs_subtracted, 0, 0.6, target))\n",
    "    \n",
    "    df_subtracted = df_subtracted.assign(\n",
    "    events = epochs_subtracted.events[:,2],\n",
    "    label = lambda df: df.events.apply(lambda x: make_str_label(x)).str.split('/'), \n",
    "    probe = lambda df: df.label.apply(lambda x: x[0]),\n",
    "    mind = lambda df: df.label.apply(lambda x: x[1]),\n",
    "    stimuli = lambda df: df.label.apply(lambda x: x[2]),\n",
    "    correct = lambda df: df.label.apply(lambda x: x[3]), \n",
    "    prev_trial = lambda df: df.label.apply(lambda x: x[4]),\n",
    "    segment = lambda df: df.label.apply(lambda x: x[5]),\n",
    "    preproc = 'subtracted',\n",
    "    epoch_type = epoch_type\n",
    "    )\n",
    "    \n",
    "    df_markers = df_markers.append(df_subtracted)\n",
    "        \n",
    "    ##################\n",
    "    #### With ERP ####\n",
    "    ##################\n",
    "    epochs_erp = mne.read_epochs(folder +  participant + '_' + epoch_type + '_' +  'ar_rereferenced_epo.fif')\n",
    "    epochs_erp.info['description'] = 'biosemi/64' #necessary for wSMI\n",
    "    epochs_erp =  epochs_erp.pick_types(eeg = True) #EOGs break everything\n",
    "    \n",
    "    df_erp = pd.DataFrame.from_dict(all_markers(epochs_erp, 0, 0.6, target))\n",
    "    \n",
    "    df_erp = df_erp.assign(\n",
    "    events = epochs_erp.events[:,2],\n",
    "    label = lambda df: df.events.apply(lambda x: make_str_label(x)).str.split('/'), \n",
    "    probe = lambda df: df.label.apply(lambda x: x[0]),\n",
    "    mind = lambda df: df.label.apply(lambda x: x[1]),\n",
    "    stimuli = lambda df: df.label.apply(lambda x: x[2]),\n",
    "    correct = lambda df: df.label.apply(lambda x: x[3]), \n",
    "    prev_trial = lambda df: df.label.apply(lambda x: x[4]),\n",
    "    segment = lambda df: df.label.apply(lambda x: x[5]),\n",
    "    preproc = 'erp',\n",
    "    epoch_type = epoch_type\n",
    "    )\n",
    "    df_markers = df_markers.append(df_erp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df_markers.to_csv(folder+ participant + '_' + epoch_type + '_all_marker.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
